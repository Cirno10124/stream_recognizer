#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯¦ç»†çš„OCRè°ƒè¯•è„šæœ¬ - å¸®åŠ©æ’æŸ¥å­—å¹•è¯†åˆ«é—®é¢˜
"""

import os
import sys
import cv2
import numpy as np

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

def debug_ocr_step_by_step(video_path):
    """é€æ­¥è°ƒè¯•OCRè¯†åˆ«è¿‡ç¨‹"""
    try:
        from tools.ocr.improved_ocr_extractor import ImprovedOCRExtractor
        
        print("=== è¯¦ç»†OCRè°ƒè¯• ===\n")
        
        # 1. åˆå§‹åŒ–OCR
        print("1. åˆå§‹åŒ–OCRæå–å™¨...")
        extractor = ImprovedOCRExtractor(
            languages=['ch', 'en'],
            use_gpu=False,
            engine='paddleocr'
        )
        print(f"âœ… OCRå¼•æ“: {extractor.engine_name}")
        
        # 2. æ‰“å¼€è§†é¢‘
        print(f"\n2. æ‰“å¼€è§†é¢‘: {video_path}")
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
            return False
        
        # è·å–è§†é¢‘ä¿¡æ¯
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        print(f"âœ… è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps:.1f}fps, {total_frames}å¸§")
        
        # 3. æµ‹è¯•å¤šä¸ªå­—å¹•åŒºåŸŸ
        regions = [
            ("åº•éƒ¨30%", 0, int(height * 0.7), width, height),
            ("åº•éƒ¨20%", 0, int(height * 0.8), width, height),
            ("åº•éƒ¨40%", 0, int(height * 0.6), width, height),
            ("å…¨å±", 0, 0, width, height)
        ]
        
        # 4. æµ‹è¯•å‡ ä¸ªä¸åŒçš„å¸§
        test_frames = [30, 60, 120, 180, 300]
        
        for frame_idx, frame_num in enumerate(test_frames):
            if frame_num >= total_frames:
                continue
                
            print(f"\n=== æµ‹è¯•å¸§ {frame_num} (æ—¶é—´: {frame_num/fps:.1f}s) ===")
            
            # è·³è½¬åˆ°æŒ‡å®šå¸§
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
            ret, frame = cap.read()
            
            if not ret:
                print("âŒ æ— æ³•è¯»å–å¸§")
                continue
            
            # æµ‹è¯•ä¸åŒçš„å­—å¹•åŒºåŸŸ
            for region_name, x1, y1, x2, y2 in regions:
                print(f"\n--- åŒºåŸŸ: {region_name} ({x1},{y1},{x2},{y2}) ---")
                
                region_img = frame[y1:y2, x1:x2]
                
                # ä¿å­˜åŸå§‹åŒºåŸŸ
                original_path = f"debug_f{frame_idx+1}_{region_name.replace('%', 'p')}_original.png"
                cv2.imwrite(original_path, region_img)
                print(f"ğŸ’¾ åŸå§‹åŒºåŸŸ: {original_path}")
                
                # æµ‹è¯•ä¸åŒé¢„å¤„ç†æ–¹æ³•
                methods = ['none', 'minimal']
                
                for method in methods:
                    print(f"  ğŸ”„ é¢„å¤„ç†: {method}")
                    
                    if method == 'none':
                        processed_img = region_img
                    else:
                        processed_img = extractor._preprocess_image(region_img, method=method)
                    
                    # ä¿å­˜é¢„å¤„ç†ç»“æœ
                    processed_path = f"debug_f{frame_idx+1}_{region_name.replace('%', 'p')}_{method}.png"
                    cv2.imwrite(processed_path, processed_img)
                    
                    # OCRè¯†åˆ« - ä½¿ç”¨æä½ç½®ä¿¡åº¦
                    try:
                        text = extractor._ocr_recognize(processed_img, confidence_threshold=0.05)
                        cleaned_text = extractor._clean_text(text)
                        
                        print(f"    ğŸ” åŸå§‹: '{text}'")
                        print(f"    âœ¨ æ¸…ç†: '{cleaned_text}'")
                        
                        if cleaned_text:
                            print(f"    âœ… æˆåŠŸ! åŒºåŸŸ:{region_name}, é¢„å¤„ç†:{method}")
                            
                    except Exception as e:
                        print(f"    âŒ OCRé”™è¯¯: {e}")
        
        cap.release()
        return True
        
    except Exception as e:
        print(f"âŒ è°ƒè¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_paddleocr_basic():
    """æµ‹è¯•PaddleOCRåŸºæœ¬åŠŸèƒ½"""
    try:
        print("\n=== PaddleOCRåŸºæœ¬æµ‹è¯• ===")
        
        from paddleocr import PaddleOCR
        
        # æµ‹è¯•å¤šç§è¯­è¨€é…ç½®
        configs = [
            ('ch', 'ä¸­æ–‡'),
            ('en', 'è‹±æ–‡'),
            (['ch', 'en'], 'ä¸­è‹±æ–‡æ··åˆ')
        ]
        
        for lang, desc in configs:
            print(f"\n--- æµ‹è¯•è¯­è¨€: {desc} ---")
            try:
                ocr = PaddleOCR(use_textline_orientation=True, lang=lang, device='cpu')
                
                # åˆ›å»ºæµ‹è¯•å›¾åƒ
                test_img = np.ones((100, 400, 3), dtype=np.uint8) * 255
                cv2.putText(test_img, 'Hello ä½ å¥½', (20, 60),
                           cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 2)
                
                # OCRè¯†åˆ«
                results = ocr.ocr(test_img)
                print(f"âœ… {desc} é…ç½®æˆåŠŸ")
                
                if results and results[0]:
                    for line in results[0]:
                        if line and len(line) >= 2:
                            text_info = line[1]
                            if isinstance(text_info, (list, tuple)) and len(text_info) >= 2:
                                text, confidence = text_info[0], text_info[1]
                                print(f"    è¯†åˆ«: '{text}' (ç½®ä¿¡åº¦: {confidence:.3f})")
                
            except Exception as e:
                print(f"âŒ {desc} é…ç½®å¤±è´¥: {e}")
        
        return True
        
    except Exception as e:
        print(f"âŒ PaddleOCRæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("=== OCRè¯¦ç»†è°ƒè¯•å·¥å…· ===")
    
    # å…ˆæµ‹è¯•PaddleOCRåŸºæœ¬åŠŸèƒ½
    test_paddleocr_basic()
    
    # ç„¶åæµ‹è¯•è§†é¢‘OCR
    if len(sys.argv) > 1:
        video_path = sys.argv[1]
        if os.path.exists(video_path):
            print(f"\nå¼€å§‹è°ƒè¯•è§†é¢‘: {video_path}")
            debug_ocr_step_by_step(video_path)
        else:
            print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
    else:
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("python debug_ocr_detailed.py <è§†é¢‘æ–‡ä»¶è·¯å¾„>")
        print("æˆ–è€…å°†è§†é¢‘æ–‡ä»¶æ‹–æ‹½åˆ°æ­¤è„šæœ¬ä¸Š")

if __name__ == "__main__":
    main() 