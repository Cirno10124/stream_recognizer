#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•æµ‹è¯•ä¿®å¤åçš„å‚æ•°
"""

import sys
import os
import cv2
import numpy as np
from pathlib import Path

# æ·»åŠ è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

def check_paddleocr():
    """æ£€æŸ¥PaddleOCRå®‰è£…å’Œåˆå§‹åŒ–"""
    try:
        from paddleocr import PaddleOCR
        
        # æ£€æŸ¥CUDA
        try:
            import paddle
            cuda_available = paddle.device.is_compiled_with_cuda()
            gpu_count = paddle.device.cuda.device_count()
            print(f"CUDAå¯ç”¨: {cuda_available}, GPUæ•°é‡: {gpu_count}")
        except:
            cuda_available = False
            gpu_count = 0
        
        # é€‰æ‹©è®¾å¤‡
        device = 'gpu' if cuda_available and gpu_count > 0 else 'cpu'
        print(f"ä½¿ç”¨è®¾å¤‡: {device}")
        
        # åˆå§‹åŒ–PaddleOCR - ä»…ä½¿ç”¨å…¼å®¹å‚æ•°
        print("æ­£åœ¨åˆå§‹åŒ–PaddleOCR...")
        ocr = PaddleOCR(
            use_textline_orientation=True,
            lang='ch',
            device=device
        )
        
        print("âœ… PaddleOCRåˆå§‹åŒ–æˆåŠŸ!")
        return ocr
        
    except Exception as e:
        print(f"âŒ PaddleOCRåˆå§‹åŒ–å¤±è´¥: {e}")
        return None

def extract_frame_region(video_path, frame_number=100):
    """æå–è§†é¢‘å¸§çš„å­—å¹•åŒºåŸŸ"""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
        return None
    
    # è·å–è§†é¢‘ä¿¡æ¯
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    print(f"è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps:.1f}fps, {total_frames}å¸§")
    
    # è·³åˆ°æŒ‡å®šå¸§
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
    ret, frame = cap.read()
    cap.release()
    
    if not ret:
        print(f"âŒ æ— æ³•è¯»å–ç¬¬{frame_number}å¸§")
        return None
    
    # æå–ä¸‹30%åŒºåŸŸä½œä¸ºå­—å¹•åŒºåŸŸ
    subtitle_y_start = int(height * 0.7)
    subtitle_region = frame[subtitle_y_start:height, 0:width]
    
    print(f"å­—å¹•åŒºåŸŸå°ºå¯¸: {subtitle_region.shape}")
    
    # ä¿å­˜åŸå§‹åŒºåŸŸ
    cv2.imwrite("test_subtitle_region.png", subtitle_region)
    print("å·²ä¿å­˜å­—å¹•åŒºåŸŸ: test_subtitle_region.png")
    
    return subtitle_region

def preprocess_for_ocr(image):
    """é¢„å¤„ç†å›¾åƒ"""
    # è½¬ç°åº¦
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image
    
    # è½»å¾®å¢å¼ºå¯¹æ¯”åº¦
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)
    
    # ä¿å­˜å¤„ç†åçš„å›¾åƒ
    cv2.imwrite("test_processed_region.png", enhanced)
    print("å·²ä¿å­˜å¤„ç†åå›¾åƒ: test_processed_region.png")
    
    return enhanced

def test_ocr_recognition(ocr, image, confidence_threshold=0.1):
    """æµ‹è¯•OCRè¯†åˆ«"""
    print(f"\nå¼€å§‹OCRè¯†åˆ« (ç½®ä¿¡åº¦é˜ˆå€¼: {confidence_threshold})...")
    
    try:
        results = ocr.ocr(image)
        
        if results and results[0] is not None:
            print(f"è¯†åˆ«åˆ° {len(results[0])} ä¸ªæ–‡æœ¬å—")
            texts = []
            
            for i, line in enumerate(results[0]):
                if line and len(line) >= 2:
                    bbox = line[0]
                    text_info = line[1]
                    if isinstance(text_info, (list, tuple)) and len(text_info) >= 2:
                        text, confidence = text_info[0], text_info[1]
                        print(f"  {i+1}. æ–‡æœ¬: '{text}' | ç½®ä¿¡åº¦: {confidence:.3f}")
                        
                        if confidence >= confidence_threshold:
                            texts.append(text)
            
            final_text = ' '.join(texts)
            print(f"\næœ€ç»ˆè¯†åˆ«ç»“æœ: '{final_text}'")
            return final_text
        else:
            print("âŒ æœªè¯†åˆ«åˆ°ä»»ä½•æ–‡æœ¬")
            return ""
            
    except Exception as e:
        print(f"âŒ OCRè¯†åˆ«å¤±è´¥: {e}")
        return ""

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python simple_test_fix.py <è§†é¢‘æ–‡ä»¶è·¯å¾„>")
        return
    
    video_path = sys.argv[1]
    if not os.path.exists(video_path):
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return
    
    print(f"ğŸ¬ æµ‹è¯•è§†é¢‘: {Path(video_path).name}")
    
    # 1. æ£€æŸ¥PaddleOCR
    ocr = check_paddleocr()
    if not ocr:
        return
    
    # 2. æå–å­—å¹•åŒºåŸŸ
    subtitle_region = extract_frame_region(video_path, frame_number=500)  # æµ‹è¯•ç¬¬500å¸§
    if subtitle_region is None:
        return
    
    # 3. é¢„å¤„ç†
    processed_image = preprocess_for_ocr(subtitle_region)
    
    # 4. æµ‹è¯•ä¸åŒç½®ä¿¡åº¦é˜ˆå€¼
    confidence_thresholds = [0.05, 0.1, 0.2, 0.3]
    
    for threshold in confidence_thresholds:
        print(f"\n{'='*50}")
        result = test_ocr_recognition(ocr, processed_image, threshold)
        if result:
            print(f"âœ… ç½®ä¿¡åº¦ {threshold}: æˆåŠŸè¯†åˆ«åˆ°æ–‡æœ¬!")
            break
        else:
            print(f"âŒ ç½®ä¿¡åº¦ {threshold}: æœªè¯†åˆ«åˆ°æ–‡æœ¬")
    
    print(f"\nğŸ¯ æµ‹è¯•å®Œæˆï¼æ£€æŸ¥ä»¥ä¸‹æ–‡ä»¶:")
    print("  - test_subtitle_region.png (åŸå§‹å­—å¹•åŒºåŸŸ)")
    print("  - test_processed_region.png (å¤„ç†åçš„å›¾åƒ)")

if __name__ == "__main__":
    main() 